{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DEP TASK 4**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Data Collection And preprocessing**"
      ],
      "metadata": {
        "id": "dkIRV6wfVDsn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv7FC1VaWwZv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the network traffic data\n",
        "data = pd.read_csv('/content/network_traffic_data.csv')"
      ],
      "metadata": {
        "id": "r6FdH9T3inwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = data.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Scale numerical columns only\n",
        "scaler = StandardScaler()\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])"
      ],
      "metadata": {
        "id": "8f0crINOikJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example feature extraction\n",
        "data['packet_size_diff'] = data['PacketCount'].diff().fillna(0)\n",
        "data['time_interval'] = data['Duration'].diff().fillna(0)"
      ],
      "metadata": {
        "id": "sRtlB4ds_Q7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Isolalation Forest Algo**"
      ],
      "metadata": {
        "id": "KOe5DOV9bNzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Isolation Forest model\n",
        "model = IsolationForest(contamination=0.01)\n",
        "model.fit(data[numerical_cols])\n",
        "\n",
        "# Predict anomalies\n",
        "data['anomaly'] = model.predict(data[numerical_cols])"
      ],
      "metadata": {
        "id": "Fzlg0QhEAy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['anomaly'] = data['anomaly'].map({-1: 'Attack', 1: 'Normal'})\n",
        "\n",
        "ground_truth = data['Label']\n",
        "\n",
        "print(classification_report(ground_truth, data['anomaly']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aD7BiSWBD-J",
        "outputId": "c05aa0f9-cbc5-4d08-f72b-71223cb8e5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Attack       0.55      0.01      0.02      1022\n",
            "      Normal       0.49      0.99      0.66       978\n",
            "\n",
            "    accuracy                           0.49      2000\n",
            "   macro avg       0.52      0.50      0.34      2000\n",
            "weighted avg       0.52      0.49      0.33      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Autoencoder Algo**"
      ],
      "metadata": {
        "id": "oavpF7Zcbs2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKYdNgKrcQAJ",
        "outputId": "a6b188a5-621e-4022-ca6c-beccb6e7e1d5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VeWP5UNocBVj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(data[numerical_cols], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "l5djq2QNcadl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the autoencoder architecture\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 14  # Dimension of the latent space\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
        "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the autoencoder\n",
        "history = autoencoder.fit(X_train, X_train,\n",
        "                          epochs=50,\n",
        "                          batch_size=16,\n",
        "                          validation_data=(X_test, X_test),\n",
        "                          shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m57AQGPcHwm",
        "outputId": "9d125f3f-6315-49f6-f11c-737ad04a4eaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.1372 - val_loss: 1.0387\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.9872 - val_loss: 0.9097\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.8764 - val_loss: 0.8159\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.7943 - val_loss: 0.7441\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7303 - val_loss: 0.6865\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6803 - val_loss: 0.6417\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6428 - val_loss: 0.6089\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 0.5868\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5987 - val_loss: 0.5719\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 0.5617\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5784 - val_loss: 0.5544\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5724 - val_loss: 0.5491\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5678 - val_loss: 0.5450\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5642 - val_loss: 0.5418\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5392\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5591 - val_loss: 0.5371\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 0.5353\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.5339\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 0.5327\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5532 - val_loss: 0.5316\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 0.5308\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5515 - val_loss: 0.5300\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5508 - val_loss: 0.5294\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5502 - val_loss: 0.5288\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5496 - val_loss: 0.5283\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5492 - val_loss: 0.5279\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5488 - val_loss: 0.5275\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5484 - val_loss: 0.5272\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5481 - val_loss: 0.5269\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5478 - val_loss: 0.5266\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5476 - val_loss: 0.5264\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5473 - val_loss: 0.5262\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.5260\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5470 - val_loss: 0.5258\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.5257\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.5256\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.5254\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.5253\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5462 - val_loss: 0.5252\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5461 - val_loss: 0.5251\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5250\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.5249\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.5248\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5458 - val_loss: 0.5248\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.5247\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5247\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.5246\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5455 - val_loss: 0.5245\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.5245\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5454 - val_loss: 0.5244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruct the test data\n",
        "X_test_pred = autoencoder.predict(X_test)\n",
        "\n",
        "# Calculate the reconstruction error\n",
        "mse = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
        "\n",
        "# Determine a threshold for anomaly detection\n",
        "threshold = np.percentile(mse, 95)\n",
        "\n",
        "# Identify anomalies\n",
        "anomalies = mse > threshold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyLYjoVPc9m-",
        "outputId": "1b83a416-3c22-45ac-d136-283d4f6d1a31"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = data['Label'][len(X_train):]  # Use the test set portion\n",
        "\n",
        "anomalies_str = np.where(anomalies, 'Attack', 'Normal')\n",
        "\n",
        "print(classification_report(ground_truth, anomalies_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQqWqu21dPut",
        "outputId": "b618097d-d7f0-4bf6-c605-626ac28cf828"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Attack       0.50      0.05      0.09       198\n",
            "      Normal       0.51      0.95      0.66       202\n",
            "\n",
            "    accuracy                           0.51       400\n",
            "   macro avg       0.50      0.50      0.38       400\n",
            "weighted avg       0.50      0.51      0.38       400\n",
            "\n"
          ]
        }
      ]
    }
  ]
}